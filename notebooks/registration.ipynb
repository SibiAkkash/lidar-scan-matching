{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pcd(file, out_file='pcd.txt', height=0):\n",
    "    \"\"\" write one measurement per angle to out file (in euclidean format) \"\"\"\n",
    "    angles = []\n",
    "    distances = []\n",
    "    seen = set()\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            angle, dist, quality = map(lambda x : float(x.split(':')[1]), line.split())\n",
    "            angle = math.floor(angle)\n",
    "            if angle not in seen:\n",
    "                angles.append(math.radians(angle))\n",
    "                distances.append(dist)\n",
    "                seen.add(angle)\n",
    "\n",
    "    angles = np.array(angles)\n",
    "    distances = np.array(distances)\n",
    "    \n",
    "    points_x = np.cos(angles) * distances\n",
    "    points_y = np.sin(angles) * distances\n",
    "\n",
    "    # write in x y z format for open3d\n",
    "    with open(out_file, 'w') as f:\n",
    "        for x, y in zip(points_x, points_y):\n",
    "            f.write(f'{x} {y} {height}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert files to required xyz format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH_RAW_POINTS = \"../data/out\"\n",
    "BASE_PATH_POINTS = \"../data/out_uni\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pcd(f'{BASE_PATH_RAW_POINTS}/1.txt', out_file=f'{BASE_PATH_POINTS}/1.txt')\n",
    "write_pcd(f'{BASE_PATH_RAW_POINTS}/2.txt', out_file=f'{BASE_PATH_POINTS}/2.txt')\n",
    "write_pcd(f'{BASE_PATH_RAW_POINTS}/3.txt', out_file=f'{BASE_PATH_POINTS}/3.txt')\n",
    "write_pcd(f'{BASE_PATH_RAW_POINTS}/4.txt', out_file=f'{BASE_PATH_POINTS}/4.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_1 = o3d.io.read_point_cloud(f\"{BASE_PATH_POINTS}/1.txt\", format='xyz')\n",
    "pcd_2 = o3d.io.read_point_cloud(f\"{BASE_PATH_POINTS}/2.txt\", format='xyz')\n",
    "pcd_3 = o3d.io.read_point_cloud(f\"{BASE_PATH_POINTS}/3.txt\", format='xyz')\n",
    "pcd_4 = o3d.io.read_point_cloud(f\"{BASE_PATH_POINTS}/4.txt\", format='xyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan matching\n",
    "Since we have a 2D lidar, we have to take scans of the room at multiple heights to construct a model of the room. A 2D lidar gives a floor plan like output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample scan\n",
    "o3d.visualization.draw_geometries([pcd_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take measurements at different heights and stack them to get a 3D model. The scans taken at each height **will not be of the same orientation** due to slight movements. This is true in the case of a drone where vibrations and small translations could give a **translated and/or rotated scan**, when compared to the previous scan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can identify some **keypoints/features/corresponding** points between 2 scans, we can match them by applying a rigid body transformation (a room is rigid).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view subsequent scans\n",
    "o3d.visualization.draw_geometries([pcd_1, pcd_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple heuristic will be the closest neighbour of a point. If we consider a point in a scan and find the closest point to it in the next scan, there is a high change that those **2 points have a correspondence** (here correspondence means that those points are of the same location in the room).\n",
    "\n",
    "##### To align the point clouds, we need to minimize the distance between these corresponding pairs of points.\n",
    "\n",
    "Once we find the distance between the point pairs, we estimate a rigid body transformation which will align these 2 scans. Solving a system of linear equations gives us a rotation and translation matrix.\n",
    "\n",
    "Since we've used a heuristic, we don't know whether this is the optimal match for the scans. We use an error metric like root mean squared error to calculate the distance between the 2 scans, _after_ the transformation. **Our goal is to minimize this RMSE**, we repeat the above steps until the error(distance between scans) is low enough. \n",
    "\n",
    "Since the error metric calculates the point to point euclidean distance, the algorithm is called Point to Point ICP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/ICP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) We don't know the corresponding points, find them using the nearest neighbour heuristic.\n",
    "\n",
    "##### 2) Once we have the corresponding points, find the transformation that minimizes the distance between the point clouds (Distance measure is Euclidean distance). Given corresponding points, we know that one point cloud is **translated and rotated** by some matrix T and R respectively, from the target point cloud.\n",
    "\n",
    "<img src=\"../images/given.png\"/>\n",
    "<br />\n",
    "\n",
    "##### 3) The error metric used is squared error, we have to solve this least squares problem to get the optimal transformation.\n",
    "<img src=\"../images/problem.png\" />\n",
    "<br />\n",
    "\n",
    "##### 4) We can move the both the point clouds to the origin, by subtracting the centroids of each point cloud\n",
    "<img src=\"../images/com.png\" />\n",
    "<br />\n",
    "\n",
    "##### 5) We can solve this problem in one shot by calculating the SVD of the given matrix\n",
    "<img src=\"../images/svd.png\" />\n",
    "<br />\n",
    "\n",
    "##### 6) The optimal matrices are \n",
    "<img src=\"../images/matrices.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source, source_temp, target_temp],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_1_copy = copy.deepcopy(pcd_1)\n",
    "pcd_2_copy = copy.deepcopy(pcd_2)\n",
    "pcd_3_copy = copy.deepcopy(pcd_3)\n",
    "pcd_4_copy = copy.deepcopy(pcd_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=9.972222e-01, inlier_rmse=1.462995e+01, and correspondence_set size of 359\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 9.99348867e-01  3.60810385e-02  0.00000000e+00  3.88657061e+01]\n",
      " [-3.60810385e-02  9.99348867e-01  0.00000000e+00  1.61643649e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=2.493350e+01, and correspondence_set size of 360\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[  0.97493107   0.2225071    0.          13.56550903]\n",
      " [ -0.2225071    0.97493107   0.         -61.92267342]\n",
      " [  0.           0.           1.           0.        ]\n",
      " [  0.           0.           0.           1.        ]]\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=2.657564e+01, and correspondence_set size of 360\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[  0.98285917  -0.18435795   0.         -10.58415239]\n",
      " [  0.18435795   0.98285917   0.         -36.01000517]\n",
      " [  0.           0.           1.           0.        ]\n",
      " [  0.           0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# this is our base scan, we are matching all other scans to this\n",
    "target = pcd_1_copy\n",
    "# other point clouds\n",
    "sources = [pcd_2_copy, pcd_3_copy, pcd_4_copy]\n",
    "\n",
    "# initial transformation guess\n",
    "trans_init = np.eye(4,4)\n",
    "\n",
    "for source in sources:\n",
    "\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, \n",
    "        target, \n",
    "        200, \n",
    "        trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000)\n",
    "    )\n",
    "\n",
    "    print(reg_p2p)\n",
    "    print(\"Transformation is:\")\n",
    "    print(reg_p2p.transformation)\n",
    "\n",
    "    source.transform(reg_p2p.transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise(pcd_1, pcd_2, pcd_3, pcd_4, pcd_1_copy, pcd_2_copy, pcd_3_copy, pcd_4_copy):\n",
    "    # Original point cloud\n",
    "    pcd_1.translate((0,0,600))\n",
    "    pcd_2.translate((0,0,1000))\n",
    "    pcd_3.translate((0,0,1400))\n",
    "    pcd_4.translate((0,0,1800))\n",
    "\n",
    "    pcd_1.paint_uniform_color([0.8, 0, 0])\n",
    "    pcd_2.paint_uniform_color([0, 0.8, 0])\n",
    "    pcd_3.paint_uniform_color([0, 0, 0.8])\n",
    "    pcd_4.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "\n",
    "    # matched point cloud\n",
    "    pcd_1_copy.translate((6000,0,600))\n",
    "    pcd_2_copy.translate((6000,0,1000))\n",
    "    pcd_3_copy.translate((6000,0,1400))\n",
    "    pcd_4_copy.translate((6000,0,1800))\n",
    "\n",
    "    pcd_1_copy.paint_uniform_color([0.8, 0, 0])\n",
    "    pcd_2_copy.paint_uniform_color([0, 0.8, 0])\n",
    "    pcd_3_copy.paint_uniform_color([0, 0, 0.8])\n",
    "    pcd_4_copy.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [\n",
    "            pcd_1_copy, pcd_2_copy, pcd_3_copy, pcd_4_copy,\n",
    "            pcd_1, pcd_2, pcd_3, pcd_4\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise(pcd_1, pcd_2, pcd_3, pcd_4, pcd_1_copy, pcd_2_copy, pcd_3_copy, pcd_4_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    "- We assume that subsequent scans will have some corresponding points. \n",
    "- If the lidar frequency is slower than the movement of the drone, there wont be much overlap between subsequent scans.\n",
    "- ICP works best when the movements are not too drastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drastic change in subsequent scans will fail to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_1_temp = o3d.io.read_point_cloud(\"../data/sme_uni/sm_points_3.txt\", format='xyz')\n",
    "pcd_2_temp = o3d.io.read_point_cloud(\"../data/sme_uni/sm_points_side.txt\", format='xyz')\n",
    "\n",
    "pcd_1_temp_c = copy.deepcopy(pcd_1_temp)\n",
    "pcd_2_temp_c = copy.deepcopy(pcd_2_temp)\n",
    "\n",
    "pcd_1_temp_c.paint_uniform_color([1, 0.706, 0])\n",
    "pcd_1_temp.paint_uniform_color([1, 0.706, 0])\n",
    "pcd_2_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "pcd_2_temp_c.paint_uniform_color([0, 0.651, 0.929])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_1_temp, pcd_2_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        pcd_2_temp_c, \n",
    "        pcd_1_temp_c, \n",
    "        300, \n",
    "        np.eye(4,4),\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000)\n",
    "    )\n",
    "\n",
    "pcd_2_temp_c.transform(reg_p2p.transformation)\n",
    "\n",
    "\n",
    "pcd_1_temp.translate((0, 0, 0))\n",
    "pcd_2_temp.translate((0, 0, 600))\n",
    "pcd_1_temp_c.translate((6000, 0, 0))\n",
    "pcd_2_temp_c.translate((6000, 0, 600))\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_1_temp, pcd_2_temp, pcd_1_temp_c, pcd_2_temp_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriangleMesh with 1440 points and 1594 triangles."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine reigistered point clouds\n",
    "pcd_1_pts = np.asarray(pcd_1_copy.points)\n",
    "pcd_2_pts = np.asarray(pcd_2_copy.points)\n",
    "pcd_3_pts = np.asarray(pcd_3_copy.points)\n",
    "pcd_4_pts = np.asarray(pcd_4_copy.points)\n",
    "\n",
    "final_points = np.vstack((pcd_1_pts, pcd_2_pts, pcd_3_pts, pcd_4_pts))\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(final_points)\n",
    "\n",
    "# computer mesh using ball pivoting\n",
    "# http://www.open3d.org/docs/latest/tutorial/Advanced/surface_reconstruction.html#Ball-pivoting\n",
    "\n",
    "pcd.estimate_normals()\n",
    "pcd.orient_normals_consistent_tangent_plane(100)\n",
    "pcd.normals = o3d.utility.Vector3dVector(-np.asarray(pcd.normals))\n",
    "\n",
    "distances = pcd.compute_nearest_neighbor_distance()\n",
    "avg_dist = np.mean(distances)\n",
    "radius = 5 * avg_dist\n",
    "\n",
    "# print(radius)\n",
    "\n",
    "radii = [radius, radius * 1.5, radius * 2]\n",
    "radii = [radius * 2, radius * 2.5]\n",
    "\n",
    "bpa_mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(\n",
    "    pcd,\n",
    "    o3d.utility.DoubleVector(radii)\n",
    ")\n",
    "\n",
    "bpa_mesh.remove_degenerate_triangles()\n",
    "bpa_mesh.remove_duplicated_triangles()\n",
    "bpa_mesh.remove_duplicated_vertices()\n",
    "bpa_mesh.remove_non_manifold_edges()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd.paint_uniform_color([0, 0.5, 0])\n",
    "bpa_mesh.paint_uniform_color([0, 0, 0.5])\n",
    "o3d.visualization.draw_geometries([pcd, bpa_mesh])\n",
    "# o3d.visualization.draw_geometries([bpa_mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_color_to_mesh(mesh):\n",
    "    triangles = np.asarray(mesh.triangles).copy()\n",
    "    vertices = np.asarray(mesh.vertices).copy()\n",
    "\n",
    "    triangles_3 = np.zeros_like(triangles)\n",
    "    vertices_3 = np.zeros((len(triangles) * 3, 3), dtype=vertices.dtype)\n",
    "    vertex_colors = np.zeros((len(triangles) * 3, 3), dtype=np.float64)\n",
    "\n",
    "    for index_triangle, t in enumerate(triangles):\n",
    "        index_vertex = index_triangle * 3\n",
    "        vertices_3[index_vertex] = vertices[t[0]]\n",
    "        vertices_3[index_vertex + 1] = vertices[t[1]]\n",
    "        vertices_3[index_vertex + 2] = vertices[t[2]]\n",
    "\n",
    "        vertex_colors[index_vertex] = 0.5\n",
    "        vertex_colors[index_vertex + 1] = 0\n",
    "        vertex_colors[index_vertex + 2] = 0.8\n",
    "\n",
    "        triangles_3[index_triangle] = np.arange(index_vertex, index_vertex + 3)\n",
    "\n",
    "    mesh_return = copy.deepcopy(mesh)\n",
    "    mesh_return.triangles = o3d.utility.Vector3iVector(triangles_3)\n",
    "    mesh_return.vertices = o3d.utility.Vector3dVector(vertices_3)\n",
    "    mesh_return.vertex_colors = o3d.utility.Vector3dVector(vertex_colors)\n",
    "\n",
    "    return mesh_return\n",
    "\n",
    "\n",
    "colored_mesh = add_color_to_mesh(bpa_mesh)\n",
    "\n",
    "# o3d.visualization.draw_geometries([pcd, colored_mesh])\n",
    "o3d.visualization.draw_geometries([colored_mesh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherent point drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_1 = o3d.io.read_point_cloud(f\"{BASE_PATH_POINTS}/1.txt\", format='xyz')\n",
    "pcd_2 = o3d.io.read_point_cloud(f\"{BASE_PATH_POINTS}/2.txt\", format='xyz')\n",
    "pcd_3 = o3d.io.read_point_cloud(f\"{BASE_PATH_POINTS}/3.txt\", format='xyz')\n",
    "pcd_4 = o3d.io.read_point_cloud(f\"{BASE_PATH_POINTS}/4.txt\", format='xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'probreg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0ab62ddc19e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprobreg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpcd_1_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcd_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpcd_2_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcd_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'probreg'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from probreg import cpd\n",
    "\n",
    "pcd_1_copy = copy.deepcopy(pcd_1)\n",
    "pcd_2_copy = copy.deepcopy(pcd_2)\n",
    "pcd_3_copy = copy.deepcopy(pcd_3)\n",
    "pcd_4_copy = copy.deepcopy(pcd_4)\n",
    "\n",
    "# this is our base scan, we are matching all other scans to this\n",
    "target = pcd_1_copy\n",
    "# other point clouds\n",
    "sources = [pcd_2_copy, pcd_3_copy, pcd_4_copy]\n",
    "\n",
    "for source in sources:\n",
    "\n",
    "# compute cpd registration\n",
    "    tf_param, _, _ = cpd.registration_cpd(source, target)\n",
    "    source.points = tf_param.transform(source.points)\n",
    "\n",
    "    # draw result\n",
    "    source.paint_uniform_color([1, 0, 0])\n",
    "    target.paint_uniform_color([0, 1, 0])\n",
    "    o3d.visualization.draw_geometries([source, target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise(pcd_1, pcd_2, pcd_3, pcd_4, pcd_1_copy, pcd_2_copy, pcd_3_copy, pcd_4_copy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0aa12bf5579cf78caba855a2c0386a3f5275fa259fa513832903915fd82b38a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
